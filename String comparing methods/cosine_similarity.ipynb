{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity as function without existing Libraries\n",
    "Needed it for the case, that we use word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate the cosine similarity between two texts\n",
    "def cosine_sim(text1, text2):\n",
    "  # Tokenize and lemmatize the texts\n",
    "  tokens_1 = word_tokenize(text1)\n",
    "  tokens_2 = word_tokenize(text2)\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens_1 = [lemmatizer.lemmatize(token) for token in tokens_1]\n",
    "  tokens_2 = [lemmatizer.lemmatize(token) for token in tokens_2]\n",
    "\n",
    "  # Remove stop words from the texts\n",
    "  stop_words = set(stopwords.words(\"english\"))\n",
    "  tokens_1 = [token for token in tokens_1 if token not in stop_words]\n",
    "  tokens_2 = [token for token in tokens_2 if token not in stop_words]\n",
    "\n",
    "  # Create a TfidfVectorizer and fit it to both texts\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  tfidf_1 = vectorizer.fit_transform([text1])\n",
    "  tfidf_2 = vectorizer.transform([text2])\n",
    "\n",
    "  # Calculate the cosine similarity between the two texts\n",
    "  similarity = cosine_similarity(tfidf_1, tfidf_2)[0][0]\n",
    "\n",
    "  return similarity\n",
    "\n",
    "# Example usage\n",
    "text1 = \"This is a test text\"\n",
    "text2 = \"This is another test text\"\n",
    "similarity = cosine_sim(text1, text2)\n",
    "print(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1131)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1131)>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1131)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (v3.8.10:3d8993a744, May  3 2021, 08:55:58) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
